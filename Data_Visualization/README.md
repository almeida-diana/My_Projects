1. SENTIMENT ANALYSIS USING TWITTER API:

Every day, Global Bike Inc. produces thousands of bikes. 
Currently, the Shop Floor workers have to walk to the working stations, which are fixed to a certain place, in order to scan their products and to confirm that a new bike was completed. 
This is not only a waste of time which costs a lot of money, but also an exhausting part of the workers’ daily routine, which can make up to several kilometers a day just to confirm their charges. 
To counteract these vice president (Operations) engages production planner to do some research about various mobile devices as an alternative to the fixed working stations. 
Production planner is really enthusiastic about this idea and being a passionate Twitter user, he decides to do some analysis on Twitter data first, to get to know the opinions of users about the new iPad Pro and the Surface Pro 4. 
At lunch he tells his systems & database administrator about his ideas. 
Database administrator is always up to date on the newest technologies and suggests production planner to use GBI’s SAP HANA system for analyzing the data, as there is a brand new functionality for loading Twitter Data into the database.

Tools Used :-
  - SAP HANA
  - Twitter API
  - SAP Lumira


2. ANIMATED VISUALIZATION USING POWER BI:

Purpose of this exercise is to perform data cleaning and formatting of csv file in Python.  
Finally, I prepared an animated visualization in Power BI to display population change since 1800 for various places in the U.S.

Tools Used :-
  - python 3.6 (Jupyter Notebook)
  - Power BI


3. WEB SCRAPING USING BEAUTIFUL SOUP TOOLKIT:

Web Scrapping is a technique of extracting information from websites using computer software or applications.
The objective of this exercise is to develop skills for acquiring data using a Python technique. 

The scraper will use Python’s BeautifulSoup toolkit to parse the site’s HTML and extract the data. 
We’ll also use the Requests library to open the URL, download the HTML and pass it to BeautifulSoup.

Here, I have performed web scraping of a weather website - https://weather.com/weather/today/l/USTX1110:1:US .
Then, formatted the data in CSV using python programming and visualized the temperature of various cities in Texas using Excel.

Tools Used :-
  - python 3.6 (Jupyter Notebook)
  - Microsoft Excel

